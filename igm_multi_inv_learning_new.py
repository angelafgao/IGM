# -*- coding: utf-8 -*-
"""IGM_learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19oShgRrqugnNau0WwKlGUsWKDDPKLL5T
"""

##from google.colab import drive
#drive.mount('/content/drive')

#cd 'drive/MyDrive/ML_projects/IGM-journal'

import numpy as np
import torch
import torch.nn as nn
import torch.nn.init as init
import torch.nn.functional as functional
from torchvision import datasets, transforms
from torchvision.utils import save_image
import matplotlib.pyplot as plt
import matplotlib
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
from torch.autograd import Variable

torch.set_default_dtype(torch.float32)
import torch.optim as optim
import pickle
import math
from torch import Tensor
import json

## IMPORTS
import generative_model
import utils
import generative_model.model_utils as model_utils
import utils.training_utils as training_utils
import utils.data_utils as data_utils

# from sys import exit
import matplotlib.pyplot as plt
from torch.nn import functional as F
import random
import argparse

def main_function(args):

    # Get noisy + true data
    if 'multi' in args.task and 'compressed-sensing' in args.task:
        sigmas = [args.sigma_den, args.sigma_cs]
    elif 'multi' in args.task and 'phase-retrieval' in args.task:
        sigmas = [args.sigma_den, args.sigma_pr]
    else:
        sigmas = args.sigma
    print("noise level(s): {0}".format(sigmas))
    true, noisy, A, sigma, kernels = data_utils.get_true_and_noisy_data(image_size=args.image_size,
                                 sigma=sigmas,
                                 num_imgs_total=args.num_imgs,
                                 dataset=args.dataset,
                                 class_idx=args.class_idx,
                                 task=args.task,
                                 objective=args.objective,
                                 front_facing=args.front_facing)
    
    # Get generator:
    # - generator = neural network params
    # - G = functional form
    generator, G = model_utils.get_generator(args.latent_dim, args.image_size, args.generator_type)
    print("Generator number of parameters: {0}".format(model_utils.count_params(generator)))

    # Get latent GMM model
    models = model_utils.get_latent_model(args.latent_dim, args.num_imgs, args.latent_type)

    # Learn the IGM
    models, generator = training_utils.train_latent_gmm_and_generator(models=models,
                                          generator=generator,
                                          generator_func=G,
                                          generator_type=args.generator_type,
                                          lr=args.lr,
                                          sigma=sigmas,
                                          targets=noisy,
                                          true_imgs=true,
                                          num_samples=args.num_samples,
                                          num_imgs_show=args.num_imgs_show,
                                          num_imgs=args.num_imgs,
                                          num_epochs=args.num_epochs,
                                          As=A,
                                          task=args.task,
                                          save_img=args.save_img,
                                          dropout_val=args.dropout_val,
                                          layer_size=args.layer_size,
                                          num_layer_decoder=args.num_layer_decoder,
                                          batchGD=args.batchGD,
                                          dataset=args.dataset,
                                          class_idx=args.class_idx,
                                          seed=args.seed,
                                          GMM_EPS=args.GMM_EPS,
                                          sup_folder=args.sup_folder,
                                          folder=args.folder,
                                          latent_model=args.latent_type,
                                          image_size=args.image_size,
                                          num_channels=args.num_channels,
                                          no_entropy=args.no_entropy, 
                                          eps_fixed = args.eps_fixed)




if __name__ == "__main__":

    ################################################## SETUP ARGUMENTS ########################################################

    parser = argparse.ArgumentParser(description='Learning the IGM')

    # sigmas
    parser.add_argument('--sigma', type=float, default=None, metavar='N',
            help='noise std (default: None)')
    parser.add_argument('--sigma_den', type=float, default=0.70710678118, metavar='N',
            help='noise std (default: sqrt(0.5))')
    parser.add_argument('--sigma_cs', type=float, default=0.31622776601, metavar='N',
            help='noise std (default: sqrt(0.1))')
    parser.add_argument('--sigma_pr', type=float, default=0.31622776601, metavar='N',
            help='noise std (default: sqrt(0.1))')
    
    # optimization params
    parser.add_argument('--lr', type=float, default=1e-4, metavar='N',
            help='learning rate (default: 1e-4)')
    parser.add_argument('--num_samples', type=int, default=12, metavar='N',
            help='number of samples drawn from generator for batch size (default: 12)')
    parser.add_argument('--num_epochs', type=int, default=100000, metavar='N',
            help='number of epochs to train (default: 100000)')
    
    # dataset setup
    parser.add_argument('--dataset', type=str, default='MNIST', metavar='N',
            help='dataset to use (default: MNIST)')
    parser.add_argument('--front_facing', action='store_true', default=True,
            help='choosing only images from face dataset with faces facing forward (default: True )')
    parser.add_argument('--class_idx', type=int, default=8, metavar='N',
            help='class index for MNIST (default: 8)')
    parser.add_argument('--num_imgs', type=int, default=75, metavar='N',
            help='number of total examples (default: 75)')
    parser.add_argument('--num_imgs_show', type=int, default=5, metavar='N',
            help='number of examples to plot (default: 5)')
    parser.add_argument('--num_channels', type=int, default=1, metavar='N',
            help='either 1 or 3 (grayscale or RGB) (default: 1)')
    parser.add_argument('--image_size', type=int, default=32, metavar='N',
            help='size of image (default: 32)')
    
    # IGM architecture params
    parser.add_argument('--generator_type', type=str, default='deepdecoder', metavar='N',
            help='generator architecture to use (default: deepdecoder)')
    parser.add_argument('--latent_type', type=str, default='gmm', metavar='N',
            help='model for latent variational distribution (default: gmm)')
    parser.add_argument('--eps_fixed', action='store_true', default=False,
            help='keep epsilon fixed for gmm low rank (default: False)')
    parser.add_argument('--num_layer_decoder', type=int, default=6, metavar='N',
            help='number of layers in deep decoder (default: 6)')
    parser.add_argument('--layer_size', type=int, default=150, metavar='N',
            help='size of hidden layers of deep decoder (default: 150)')
    parser.add_argument('--dropout_val', type=float, default=1e-4, metavar='N',
            help='amount of dropout used in generator (default: 1e-4)')
    parser.add_argument('--GMM_EPS', type=float, default=1e-3, metavar='N',
            help='amount of perturbation added to gaussian latent distributions (default: 1e-3)')
    parser.add_argument('--latent_dim', type=int, default=50, metavar='N',
            help='size of latent dimension of generator (default: 50)')
    
    # problem setup
    parser.add_argument('--task', type=str, default='denoising', metavar='N',
            help='inverse problem to solve (default: denoising)')
    parser.add_argument('--objective', type=str, default='learning', metavar='N',
            help='either learn prior or perform model selection (default: learning)')
    
    # other params
    parser.add_argument('--seed', type=int, default=100, metavar='N',
            help='random seed (default: 100)')
    parser.add_argument('--save_img', action='store_true', default=True,
            help='whether or not to save while training (default: True )')
    
    parser.add_argument('--batchGD', action='store_true', default=False,
            help='use batch gradient descent (default: False )')
    parser.add_argument('--no_entropy', action='store_true', default=False,
            help='no entropy for loss (default: False )')

    args = parser.parse_args()



    torch.manual_seed(args.seed)
    torch.cuda.manual_seed(args.seed)
    np.random.seed(args.seed)
    random.seed(args.seed)

    GPU = torch.cuda.is_available()
    if GPU == True:
        torch.backends.cudnn.enabled = True
        torch.backends.cudnn.benchmark = True
        dtype = torch.cuda.FloatTensor
        print("num GPUs",torch.cuda.device_count())
    else:
        dtype = torch.FloatTensor
    import os,sys,inspect
    currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
    parentdir = os.path.dirname(currentdir)
    sys.path.insert(0,parentdir)
    
     ## Saving parameters
    if args.batchGD == True:
        args.sup_folder = "results_batched"
    else:
        args.sup_folder = "results_SGD"
    if "multi" in args.task:
        args.sup_folder += f"_multi_{args.sigma_cs}"
    if args.dataset == "MNIST" and args.class_idx is not None: 
        args.folder = f"{args.dataset}{args.image_size}{args.class_idx}_{args.latent_type}_{args.task}_{args.generator_type}_{str(args.num_imgs)}imgs_{str(args.sigma)}noise_std_dropout{args.dropout_val}_layer_size{args.layer_size}x{args.num_layer_decoder}_latent{args.latent_dim}_seed{args.seed}"
    else:
        args.folder = f"{args.dataset}{args.image_size}_{args.latent_type}_{args.task}_{args.generator_type}_{str(args.num_imgs)}imgs_{str(args.sigma)}noise_std_dropout{args.dropout_val}_layer_size{args.layer_size}x{args.num_layer_decoder}_latent{args.latent_dim}_seed{args.seed}"
    if args.latent_type == "gmm" or args.latent_type == "gmm_eye" or args.latent_type == "gmm_custom" or args.latent_type == "gmm_low_eye" or args.latent_type == "gmm_low":
        args.folder += f"_eps{args.GMM_EPS}"
    if args.latent_type == "gmm_low_eye" or args.latent_type == "gmm_low":
        args.folder += f"_{args.eps_fixed}"
    if args.no_entropy==True:
        args.folder += "_no_entropy"
    if not os.path.exists(f'./{args.sup_folder}/{args.folder}'):
        os.makedirs(f'./{args.sup_folder}/{args.folder}')
    if not os.path.exists(f'./{args.sup_folder}/{args.folder}/model_checkpoints'):
        os.makedirs(f'./{args.sup_folder}/{args.folder}/model_checkpoints')
    
    with open("{}/args.json".format(f'./{args.sup_folder}/{args.folder}'), 'w') as f:
        json.dump(args.__dict__, f, indent=2)
    
    if args.sigma is None:
        if args.dataset=="sagA_video":
            print("load matrix of sigmas")
            sigma = np.load("./utils/sigma_ngEHT_sagA_video_.5x.npz", allow_pickle=True)
        elif args.dataset == "m87":
            print("load matrix of sigmas")
            sigma = np.load("./utils/sigma_EHT2025_m87_frame.npz", allow_pickle=True)
        
        args.sigma = []
        for i in range(args.num_imgs):
            args.sigma.append(torch.tensor(sigma['arr_0'][i][np.newaxis, :, np.newaxis]).to(device))
   
    main_function(args)